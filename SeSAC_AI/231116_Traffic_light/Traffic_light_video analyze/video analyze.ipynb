{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f21e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 전 !!!\n",
    "# 아래 입,출력 동영상 파일 경로만 수정 !\n",
    "\n",
    "# # 입력 동영상 파일 경로\n",
    "# input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video_test(1).mp4'\n",
    "\n",
    "# # 출력 동영상 파일 경로\n",
    "# output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68298673",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0048771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc086032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # 입력 동영상 파일 경로\n",
    "# input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video(2).mp4'\n",
    "\n",
    "# # 출력 동영상 파일 경로\n",
    "# output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video.mp4'\n",
    "\n",
    "# # 입력 동영상 캡처\n",
    "# cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# # 입력 동영상의 프레임 크기 및 fps 가져오기\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # 출력 동영상 코덱 및 VideoWriter 설정\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))\n",
    "\n",
    "# # 프레임을 읽어서 크기 조정 후 출력 동영상에 쓰기\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # 프레임 크기 조정\n",
    "#     resized_frame = cv2.resize(frame, (640, 640))\n",
    "\n",
    "#     # 출력 동영상에 프레임 쓰기\n",
    "#     out.write(resized_frame)\n",
    "\n",
    "# # 자원 해제\n",
    "# cap.release()\n",
    "# out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90543db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1f8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ultralytics==8.0.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da44470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22db8a80510>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8308bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython import display\n",
    "#from IPython.display import display, Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# display.clear_output()\n",
    "\n",
    "# YOLO 객체 생성\n",
    "# yolo = YOLO()\n",
    "\n",
    "# verify 메서드 실행\n",
    "# yolo.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bd2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Men-in-Black\\Traffic_Light\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07d73f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.73  Python-3.11.5 torch-2.0.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 16.0 GB RAM, 644.5/931.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4707dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image as PILImage\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ultralytics.yolo.engine.model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b6181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22dc3083910>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70a822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('D:/Men-in-Black/Traffic_Light/yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c0d8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from ultralytics.yolo.engine.model import YOLO\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # YOLO 모델 로드\n",
    "# path = 'D:/Men-in-Black/Traffic_Light/best_model.pt'\n",
    "# model = YOLO(path)\n",
    "\n",
    "# # 입력 동영상 파일 경로\n",
    "# input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video(2).mp4'\n",
    "\n",
    "# # 출력 동영상 파일 경로\n",
    "# output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video_119.mp4'\n",
    "\n",
    "# # 입력 동영상 캡처\n",
    "# cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# # 입력 동영상의 프레임 크기 및 fps 가져오기\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # 출력 동영상 코덱 및 VideoWriter 설정\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))\n",
    "\n",
    "# # 비동기 처리를 위한 ThreadPoolExecutor 설정\n",
    "# executor = ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "# # 초기화 최적화\n",
    "# ret, frame = cap.read()\n",
    "# resized_frame = cv2.resize(frame, (640, 640))\n",
    "\n",
    "# # 프레임을 읽어서 크기 조정 후 Object Detection 및 출력 동영상에 쓰기\n",
    "# def process_frame(frame):\n",
    "#     resized_frame = cv2.resize(frame, (640, 640))\n",
    "#     results = model(resized_frame)\n",
    "#     for det in results.xyxy[0]:\n",
    "#         x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "#         x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "#         cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "#         cv2.putText(resized_frame, f'{model.names[int(cls)]}: {conf:.2f}', (x1, y1 - 5),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "#     out.write(resized_frame)\n",
    "#     cv2.imshow('Object Detection', resized_frame)\n",
    "\n",
    "# # tqdm을 사용하여 진행 상황 표시\n",
    "# with tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame') as pbar:\n",
    "#     with executor:\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "\n",
    "#             # 비동기 처리를 통한 프레임 처리\n",
    "#             executor.submit(process_frame, frame)\n",
    "\n",
    "#             # 진행 상황 업데이트\n",
    "#             pbar.update(1)\n",
    "\n",
    "#             # 'q' 키를 누르면 종료\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "# # 자원 해제\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99387a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from ultralytics.yolo.engine.model import YOLO\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # YOLO 모델 로드\n",
    "# path = 'D:/Men-in-Black/Traffic_Light/best_model.pt'\n",
    "# model = YOLO(path)\n",
    "\n",
    "# # 입력 동영상 파일 경로\n",
    "# input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video_test(1).mp4'\n",
    "\n",
    "# # 출력 동영상 파일 경로\n",
    "# output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video.mp4'\n",
    "\n",
    "# # 입력 동영상 캡처\n",
    "# cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# # 입력 동영상의 프레임 크기 및 fps 가져오기\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # 비동기 처리를 위한 ThreadPoolExecutor 설정\n",
    "# executor = ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "# # 출력 동영상 코덱 및 VideoWriter 설정\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))\n",
    "\n",
    "# # 초기화 최적화\n",
    "# ret, frame = cap.read()\n",
    "# resized_frame = cv2.resize(frame, (640, 640))\n",
    "\n",
    "# # tqdm을 사용하여 진행 상황 표시\n",
    "# pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame')\n",
    "\n",
    "# def process_frame(frame, pbar):\n",
    "#     resized_frame = cv2.resize(frame, (640, 640))\n",
    "#     results = model(resized_frame)\n",
    "#     for det in results.xyxy[0]:\n",
    "#         x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "#         x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "#         cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "#         cv2.putText(resized_frame, f'{model.names[int(cls)]}: {conf:.2f}', (x1, y1 - 5),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "#     out.write(resized_frame)\n",
    "#     cv2.imshow('Object Detection', resized_frame)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# # 첫 번째 프레임 저장\n",
    "# out.write(resized_frame)\n",
    "\n",
    "# # 비동기 처리를 통한 프레임 처리\n",
    "# with executor:\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # 비동기 처리를 통한 프레임 처리\n",
    "#         executor.submit(process_frame, frame, pbar)\n",
    "\n",
    "#         # 'q' 키를 누르면 종료\n",
    "#         if cv2.waitKey(60) & 0xFF == ord('q'):  # 30ms 지연 (약 33 fps)\n",
    "#             break\n",
    "\n",
    "# # 자원 해제\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f17c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from ultralytics.yolo.engine.model import YOLO\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # YOLO 모델 로드\n",
    "# path = 'D:/Men-in-Black/Traffic_Light/best_model.pt'\n",
    "# model = YOLO(path)\n",
    "\n",
    "# # 입력 동영상 파일 경로\n",
    "# input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video_test(1).mp4'\n",
    "\n",
    "# # 출력 동영상 파일 경로\n",
    "# output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video.mp4'\n",
    "\n",
    "# # 입력 동영상 캡처\n",
    "# cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# # 입력 동영상의 프레임 크기 및 fps 가져오기\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # 출력 동영상 코덱 및 VideoWriter 설정\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))\n",
    "\n",
    "# # 초기화 최적화\n",
    "# ret, frame = cap.read()\n",
    "\n",
    "# # tqdm을 사용하여 진행 상황 표시\n",
    "# pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame')\n",
    "\n",
    "# def process_frame(frame, pbar):\n",
    "#     resized_frame = cv2.resize(frame, (640, 640))\n",
    "#     results = model(resized_frame)\n",
    "\n",
    "#     if isinstance(results, list):  # Check if results is a list\n",
    "#         results = results[0]\n",
    "\n",
    "#     if 'xyxy' in results.names:\n",
    "#         for det in results.xyxy[0]:\n",
    "#             x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "#             x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "#             cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "#             cv2.putText(resized_frame, f'{model.names[int(cls)]}: {conf:.2f}', (x1, y1 - 5),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "#     else:\n",
    "#         print(\"Results format not recognized.\")\n",
    "\n",
    "#     out.write(resized_frame)\n",
    "#     cv2.imshow('Object Detection', resized_frame)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# # 프레임 처리\n",
    "# while ret:\n",
    "#     process_frame(frame, pbar)\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "# # 자원 해제\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b46f810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.yolo.engine.model import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# YOLO 모델 로드\n",
    "path = 'D:/Men-in-Black/Traffic_Light/best_model.pt'\n",
    "model = YOLO(path)\n",
    "\n",
    "# 입력 동영상 파일 경로\n",
    "input_video_path = 'D:/Men-in-Black/Traffic_Light/input_video_test(1).mp4'\n",
    "\n",
    "# 출력 동영상 파일 경로\n",
    "output_video_path = 'D:/Men-in-Black/Traffic_Light/output_video.mp4'\n",
    "\n",
    "# 입력 동영상 캡처\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 입력 동영상의 프레임 크기 및 fps 가져오기\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 동영상 코덱 및 VideoWriter 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "477a481a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                       | 0/276 [00:00<?, ?frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Green Light, 423.7ms\n",
      "Speed: 1.0ms preprocess, 423.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  0%|▎                                                                              | 1/276 [00:00<02:01,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290.7869873046875, 331.91253662109375, 298.12890625, 341.99761962890625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 437.0ms\n",
      "Speed: 4.8ms preprocess, 437.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                                                              | 2/276 [00:00<02:02,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290.7840270996094, 331.915771484375, 298.1399230957031, 341.9996337890625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 473.6ms\n",
      "Speed: 1.6ms preprocess, 473.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  1%|▊                                                                              | 3/276 [00:01<02:07,  2.15frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289.3324279785156, 329.7492370605469, 297.1556701660156, 340.1286926269531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 449.9ms\n",
      "Speed: 0.0ms preprocess, 449.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  1%|█▏                                                                             | 4/276 [00:01<02:06,  2.15frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 428.3ms\n",
      "Speed: 1.2ms preprocess, 428.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  2%|█▍                                                                             | 5/276 [00:02<02:03,  2.19frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Green Light, 416.8ms\n",
      "Speed: 0.0ms preprocess, 416.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  2%|█▋                                                                             | 6/276 [00:02<02:00,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286.4088134765625, 321.97479248046875, 293.3978271484375, 332.54620361328125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 420.0ms\n",
      "Speed: 0.0ms preprocess, 420.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  3%|██                                                                             | 7/276 [00:03<01:59,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Green Light, 424.0ms\n",
      "Speed: 0.0ms preprocess, 424.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  3%|██▎                                                                            | 8/276 [00:03<01:58,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.5071716308594, 314.7616271972656, 339.1194152832031, 324.2873229980469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 404.4ms\n",
      "Speed: 2.0ms preprocess, 404.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  3%|██▌                                                                            | 9/276 [00:04<01:57,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.51788330078125, 311.7365417480469, 338.67041015625, 321.2508239746094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 419.9ms\n",
      "Speed: 1.0ms preprocess, 419.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  4%|██▊                                                                           | 10/276 [00:04<01:57,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.1791076660156, 308.128173828125, 338.4692687988281, 318.51141357421875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 415.0ms\n",
      "Speed: 0.0ms preprocess, 415.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  4%|███                                                                           | 11/276 [00:04<01:55,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.27734375, 304.98468017578125, 338.52783203125, 315.47259521484375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 420.7ms\n",
      "Speed: 0.0ms preprocess, 420.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  4%|███▍                                                                          | 12/276 [00:05<01:55,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.89727783203125, 301.09100341796875, 338.27142333984375, 312.11053466796875]\n",
      "[278.93798828125, 303.91217041015625, 286.3189697265625, 314.48687744140625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 415.2ms\n",
      "Speed: 0.0ms preprocess, 415.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  5%|███▋                                                                          | 13/276 [00:05<01:55,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.24468994140625, 297.0739440917969, 338.39324951171875, 308.3054504394531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 430.1ms\n",
      "Speed: 0.0ms preprocess, 430.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  5%|███▉                                                                          | 14/276 [00:06<01:54,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.73895263671875, 292.67120361328125, 338.06475830078125, 304.54888916015625]\n",
      "[275.23394775390625, 296.63623046875, 283.17205810546875, 307.66845703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 418.8ms\n",
      "Speed: 0.0ms preprocess, 418.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  5%|████▏                                                                         | 15/276 [00:06<01:54,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.6417236328125, 288.54486083984375, 338.25714111328125, 300.37078857421875]\n",
      "[272.8683166503906, 291.8962097167969, 281.7187805175781, 303.9933166503906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 491.6ms\n",
      "Speed: 0.0ms preprocess, 491.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  6%|████▌                                                                         | 16/276 [00:07<01:59,  2.17frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[271.7680969238281, 287.58843994140625, 280.2548522949219, 299.49566650390625]\n",
      "[329.26092529296875, 284.241943359375, 337.77362060546875, 296.03167724609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Green Light, 419.9ms\n",
      "Speed: 0.0ms preprocess, 419.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  6%|████▊                                                                         | 17/276 [00:07<01:57,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328.97943115234375, 278.9085693359375, 338.00579833984375, 290.9822998046875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 415.7ms\n",
      "Speed: 0.0ms preprocess, 415.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  7%|█████                                                                         | 18/276 [00:08<01:55,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328.6061706542969, 272.90032958984375, 337.5747375488281, 285.65826416015625]\n",
      "[267.74957275390625, 277.323974609375, 276.77667236328125, 289.9359130859375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 436.6ms\n",
      "Speed: 0.0ms preprocess, 436.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  7%|█████▎                                                                        | 19/276 [00:08<01:55,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266.170654296875, 272.3779296875, 275.08123779296875, 284.767822265625]\n",
      "[328.1568603515625, 267.8424072265625, 337.5557861328125, 280.765625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 391.9ms\n",
      "Speed: 6.7ms preprocess, 391.9ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  7%|█████▋                                                                        | 20/276 [00:08<01:52,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[327.89031982421875, 261.6767883300781, 337.16522216796875, 274.9826965332031]\n",
      "[263.39892578125, 266.7420654296875, 272.9942626953125, 280.174560546875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 419.0ms\n",
      "Speed: 0.6ms preprocess, 419.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  8%|█████▉                                                                        | 21/276 [00:09<01:52,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262.30511474609375, 260.49664306640625, 271.02423095703125, 274.09381103515625]\n",
      "[327.7098083496094, 255.38201904296875, 336.8486633300781, 269.22222900390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 405.9ms\n",
      "Speed: 0.0ms preprocess, 405.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  8%|██████▏                                                                       | 22/276 [00:09<01:50,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259.60101318359375, 255.0013427734375, 269.06488037109375, 267.8643798828125]\n",
      "[327.1604919433594, 248.75592041015625, 336.8385314941406, 262.9801940917969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 418.4ms\n",
      "Speed: 0.0ms preprocess, 418.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  8%|██████▌                                                                       | 23/276 [00:10<01:49,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257.05548095703125, 247.40151977539062, 266.30987548828125, 261.7641296386719]\n",
      "[326.91522216796875, 241.89385986328125, 336.67327880859375, 256.02691650390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 417.0ms\n",
      "Speed: 0.0ms preprocess, 417.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  9%|██████▊                                                                       | 24/276 [00:10<01:49,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326.780517578125, 234.95230102539062, 336.1798095703125, 249.12295532226562]\n",
      "[254.76010131835938, 240.85562133789062, 263.7189025878906, 254.65054321289062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 415.5ms\n",
      "Speed: 0.0ms preprocess, 415.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  9%|███████                                                                       | 25/276 [00:11<01:48,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326.4833068847656, 227.453369140625, 336.4828796386719, 242.34353637695312]\n",
      "[252.01043701171875, 232.92153930664062, 261.9073486328125, 248.27352905273438]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 402.7ms\n",
      "Speed: 1.0ms preprocess, 402.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "  9%|███████▎                                                                      | 26/276 [00:11<01:47,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[325.96514892578125, 219.4890594482422, 336.05767822265625, 234.93540954589844]\n",
      "[248.65084838867188, 225.19375610351562, 259.1333312988281, 240.86947631835938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 405.9ms\n",
      "Speed: 1.0ms preprocess, 405.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 10%|███████▋                                                                      | 27/276 [00:11<01:47,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[325.47125244140625, 211.19998168945312, 335.9873046875, 226.95864868164062]\n",
      "[246.05606079101562, 217.364013671875, 255.9765625, 232.4691162109375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Green Lights, 412.1ms\n",
      "Speed: 1.0ms preprocess, 412.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 10%|███████▉                                                                      | 28/276 [00:12<01:46,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324.96893310546875, 202.11495971679688, 335.9158935546875, 218.48831176757812]\n",
      "[242.62176513671875, 208.48809814453125, 252.69815063476562, 224.53070068359375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 401.4ms\n",
      "Speed: 0.0ms preprocess, 401.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 11%|████████▏                                                                     | 29/276 [00:12<01:45,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 410.0ms\n",
      "Speed: 1.0ms preprocess, 410.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 11%|████████▍                                                                     | 30/276 [00:13<01:46,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313.5001525878906, 182.4656982421875, 324.7134094238281, 199.4459228515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Yellow Lights, 400.9ms\n",
      "Speed: 0.8ms preprocess, 400.9ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 11%|████████▊                                                                     | 31/276 [00:13<01:45,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221.06454467773438, 179.1300811767578, 232.51571655273438, 196.67103576660156]\n",
      "[311.14520263671875, 171.06936645507812, 324.33038330078125, 190.284423828125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Yellow Lights, 404.0ms\n",
      "Speed: 2.0ms preprocess, 404.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████████                                                                     | 32/276 [00:14<01:44,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310.9044189453125, 159.52523803710938, 323.599853515625, 178.22183227539062]\n",
      "[216.1128692626953, 169.4236602783203, 227.6000518798828, 186.29344177246094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Yellow Lights, 400.7ms\n",
      "Speed: 0.0ms preprocess, 400.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████████▎                                                                    | 33/276 [00:14<01:44,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212.2186737060547, 156.55636596679688, 223.45606994628906, 174.06417846679688]\n",
      "[310.1531982421875, 146.43777465820312, 323.739990234375, 166.35275268554688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Yellow Lights, 398.4ms\n",
      "Speed: 1.0ms preprocess, 398.4ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████████▌                                                                    | 34/276 [00:14<01:43,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206.26699829101562, 142.96450805664062, 218.64987182617188, 162.04708862304688]\n",
      "[308.9535827636719, 132.04615783691406, 322.9327697753906, 153.2079315185547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 Yellow Lights, 439.4ms\n",
      "Speed: 0.0ms preprocess, 439.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████████▉                                                                    | 35/276 [00:15<01:45,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[307.7994384765625, 117.57112121582031, 321.1644287109375, 138.64918518066406]\n",
      "[200.70620727539062, 129.55056762695312, 213.73519897460938, 150.02761840820312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 418.4ms\n",
      "Speed: 1.0ms preprocess, 418.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 13%|██████████▏                                                                   | 36/276 [00:15<01:45,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195.72238159179688, 116.14840698242188, 206.91741943359375, 135.48777770996094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 417.9ms\n",
      "Speed: 0.0ms preprocess, 417.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 13%|██████████▍                                                                   | 37/276 [00:16<01:44,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 412.2ms\n",
      "Speed: 0.0ms preprocess, 412.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████████▋                                                                   | 38/276 [00:16<01:43,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180.55014038085938, 82.17552947998047, 196.84835815429688, 104.1161117553711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 420.6ms\n",
      "Speed: 0.0ms preprocess, 420.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 14%|███████████                                                                   | 39/276 [00:17<01:42,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 429.3ms\n",
      "Speed: 0.0ms preprocess, 429.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 14%|███████████▎                                                                  | 40/276 [00:17<01:42,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.3ms\n",
      "Speed: 0.0ms preprocess, 408.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 15%|███████████▌                                                                  | 41/276 [00:17<01:41,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 407.6ms\n",
      "Speed: 0.0ms preprocess, 407.6ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 15%|███████████▊                                                                  | 42/276 [00:18<01:41,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.0ms\n",
      "Speed: 1.0ms preprocess, 409.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 16%|████████████▏                                                                 | 43/276 [00:18<01:40,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 411.4ms\n",
      "Speed: 2.0ms preprocess, 411.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 16%|████████████▍                                                                 | 44/276 [00:19<01:40,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.8ms\n",
      "Speed: 2.0ms preprocess, 409.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 16%|████████████▋                                                                 | 45/276 [00:19<01:39,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.3ms\n",
      "Speed: 0.0ms preprocess, 404.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 17%|█████████████                                                                 | 46/276 [00:20<01:38,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 420.5ms\n",
      "Speed: 0.0ms preprocess, 420.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 17%|█████████████▎                                                                | 47/276 [00:20<01:38,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 406.9ms\n",
      "Speed: 0.0ms preprocess, 406.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 17%|█████████████▌                                                                | 48/276 [00:20<01:37,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.1ms\n",
      "Speed: 0.0ms preprocess, 409.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 18%|█████████████▊                                                                | 49/276 [00:21<01:37,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.0ms\n",
      "Speed: 0.0ms preprocess, 409.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████████████▏                                                               | 50/276 [00:21<01:36,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 501.2ms\n",
      "Speed: 0.0ms preprocess, 501.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████████████▍                                                               | 51/276 [00:22<01:42,  2.20frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 400.8ms\n",
      "Speed: 0.0ms preprocess, 400.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 19%|██████████████▋                                                               | 52/276 [00:22<01:39,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 403.0ms\n",
      "Speed: 0.0ms preprocess, 403.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 19%|██████████████▉                                                               | 53/276 [00:23<01:37,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 400.1ms\n",
      "Speed: 0.0ms preprocess, 400.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████████████▎                                                              | 54/276 [00:23<01:35,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 394.3ms\n",
      "Speed: 2.0ms preprocess, 394.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████████████▌                                                              | 55/276 [00:24<01:34,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.8ms\n",
      "Speed: 2.0ms preprocess, 404.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████████████▊                                                              | 56/276 [00:24<01:34,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 396.0ms\n",
      "Speed: 1.0ms preprocess, 396.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████████████                                                              | 57/276 [00:24<01:33,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 412.0ms\n",
      "Speed: 0.0ms preprocess, 412.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████████████▍                                                             | 58/276 [00:25<01:33,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 411.6ms\n",
      "Speed: 1.0ms preprocess, 411.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████████████▋                                                             | 59/276 [00:25<01:32,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.9ms\n",
      "Speed: 0.0ms preprocess, 404.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████████████▉                                                             | 60/276 [00:26<01:32,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.7ms\n",
      "Speed: 0.0ms preprocess, 410.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████████████▏                                                            | 61/276 [00:26<01:31,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 406.7ms\n",
      "Speed: 4.5ms preprocess, 406.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████████████▌                                                            | 62/276 [00:27<01:31,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 412.9ms\n",
      "Speed: 0.0ms preprocess, 412.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████████████▊                                                            | 63/276 [00:27<01:30,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 401.7ms\n",
      "Speed: 0.0ms preprocess, 401.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 23%|██████████████████                                                            | 64/276 [00:27<01:30,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.4ms\n",
      "Speed: 0.0ms preprocess, 410.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 24%|██████████████████▎                                                           | 65/276 [00:28<01:30,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.9ms\n",
      "Speed: 1.0ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 24%|██████████████████▋                                                           | 66/276 [00:28<01:30,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 394.3ms\n",
      "Speed: 1.0ms preprocess, 394.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 24%|██████████████████▉                                                           | 67/276 [00:29<01:29,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 402.4ms\n",
      "Speed: 1.0ms preprocess, 402.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████████████▏                                                          | 68/276 [00:29<01:29,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 406.9ms\n",
      "Speed: 0.0ms preprocess, 406.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▌                                                          | 69/276 [00:30<01:28,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.4ms\n",
      "Speed: 1.0ms preprocess, 409.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████████████▊                                                          | 70/276 [00:30<01:28,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 434.4ms\n",
      "Speed: 0.0ms preprocess, 434.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 26%|████████████████████                                                          | 71/276 [00:30<01:28,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 436.9ms\n",
      "Speed: 0.0ms preprocess, 436.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 26%|████████████████████▎                                                         | 72/276 [00:31<01:29,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 440.2ms\n",
      "Speed: 0.0ms preprocess, 440.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 26%|████████████████████▋                                                         | 73/276 [00:31<01:30,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 450.4ms\n",
      "Speed: 0.0ms preprocess, 450.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 27%|████████████████████▉                                                         | 74/276 [00:32<01:30,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 508.9ms\n",
      "Speed: 0.0ms preprocess, 508.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 27%|█████████████████████▏                                                        | 75/276 [00:32<01:34,  2.13frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 415.5ms\n",
      "Speed: 0.0ms preprocess, 415.5ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 28%|█████████████████████▍                                                        | 76/276 [00:33<01:31,  2.18frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 429.5ms\n",
      "Speed: 0.0ms preprocess, 429.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 28%|█████████████████████▊                                                        | 77/276 [00:33<01:30,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 427.4ms\n",
      "Speed: 1.0ms preprocess, 427.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████████████████                                                        | 78/276 [00:34<01:28,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 413.8ms\n",
      "Speed: 1.0ms preprocess, 413.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████████████████▎                                                       | 79/276 [00:34<01:27,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 417.9ms\n",
      "Speed: 0.0ms preprocess, 417.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████████████████▌                                                       | 80/276 [00:34<01:26,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 401.8ms\n",
      "Speed: 1.8ms preprocess, 401.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████████████████▉                                                       | 81/276 [00:35<01:25,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 426.8ms\n",
      "Speed: 0.0ms preprocess, 426.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████████████████▏                                                      | 82/276 [00:35<01:24,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 416.5ms\n",
      "Speed: 1.0ms preprocess, 416.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████████████████▍                                                      | 83/276 [00:36<01:24,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.0ms\n",
      "Speed: 1.0ms preprocess, 409.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████████████████▋                                                      | 84/276 [00:36<01:23,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.1ms\n",
      "Speed: 0.0ms preprocess, 410.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████████████████                                                      | 85/276 [00:37<01:22,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 408.1ms\n",
      "Speed: 0.0ms preprocess, 408.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████████████████▎                                                     | 86/276 [00:37<01:21,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343.9905090332031, 341.4791259765625, 351.2414855957031, 349.1790771484375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 402.9ms\n",
      "Speed: 1.0ms preprocess, 402.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████████████████▌                                                     | 87/276 [00:37<01:21,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 405.6ms\n",
      "Speed: 0.0ms preprocess, 405.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████████████████▊                                                     | 88/276 [00:38<01:19,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343.82342529296875, 338.6246337890625, 350.62353515625, 346.8634033203125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 401.2ms\n",
      "Speed: 0.0ms preprocess, 401.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████████████████▏                                                    | 89/276 [00:38<01:19,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343.2452392578125, 337.31640625, 349.9833984375, 345.3682861328125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 414.5ms\n",
      "Speed: 0.0ms preprocess, 414.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████████████████▍                                                    | 90/276 [00:39<01:19,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 394.8ms\n",
      "Speed: 10.8ms preprocess, 394.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████████████████▋                                                    | 91/276 [00:39<01:18,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 393.9ms\n",
      "Speed: 0.0ms preprocess, 393.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████████████████                                                    | 92/276 [00:40<01:17,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342.8227844238281, 332.3463134765625, 349.7456359863281, 341.28955078125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 420.8ms\n",
      "Speed: 0.0ms preprocess, 420.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████████████████▎                                                   | 93/276 [00:40<01:17,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342.5657958984375, 330.8765869140625, 349.337646484375, 339.8037109375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 402.3ms\n",
      "Speed: 0.0ms preprocess, 402.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████████████████▌                                                   | 94/276 [00:40<01:17,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 406.7ms\n",
      "Speed: 0.0ms preprocess, 406.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████████████████▊                                                   | 95/276 [00:41<01:17,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.0ms\n",
      "Speed: 0.0ms preprocess, 408.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 35%|███████████████████████████▏                                                  | 96/276 [00:41<01:16,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 405.4ms\n",
      "Speed: 0.0ms preprocess, 405.4ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 35%|███████████████████████████▍                                                  | 97/276 [00:42<01:16,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340.4100341796875, 325.138671875, 348.595703125, 333.80517578125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 406.6ms\n",
      "Speed: 0.0ms preprocess, 406.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████████████████▋                                                  | 98/276 [00:42<01:15,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340.27313232421875, 322.87750244140625, 348.37420654296875, 331.99383544921875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 413.4ms\n",
      "Speed: 0.0ms preprocess, 413.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████████████████▉                                                  | 99/276 [00:43<01:15,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340.05194091796875, 320.93475341796875, 347.96624755859375, 329.958984375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 449.1ms\n",
      "Speed: 0.0ms preprocess, 449.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████████████████▉                                                 | 100/276 [00:43<01:16,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.1ms\n",
      "Speed: 1.0ms preprocess, 409.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 37%|████████████████████████████▏                                                | 101/276 [00:43<01:15,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 420.9ms\n",
      "Speed: 0.0ms preprocess, 420.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 37%|████████████████████████████▍                                                | 102/276 [00:44<01:15,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339.0340576171875, 315.614501953125, 347.300048828125, 325.55078125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 423.0ms\n",
      "Speed: 0.0ms preprocess, 423.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 37%|████████████████████████████▋                                                | 103/276 [00:44<01:14,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.0ms\n",
      "Speed: 1.9ms preprocess, 408.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 38%|█████████████████████████████                                                | 104/276 [00:45<01:13,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 407.6ms\n",
      "Speed: 0.0ms preprocess, 407.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 38%|█████████████████████████████▎                                               | 105/276 [00:45<01:13,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.9ms\n",
      "Speed: 1.0ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 38%|█████████████████████████████▌                                               | 106/276 [00:46<01:12,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.0ms\n",
      "Speed: 0.0ms preprocess, 408.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 39%|█████████████████████████████▊                                               | 107/276 [00:46<01:12,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 411.4ms\n",
      "Speed: 0.0ms preprocess, 411.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████████████████████▏                                              | 108/276 [00:46<01:11,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.9ms\n",
      "Speed: 1.0ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████████████████████▍                                              | 109/276 [00:47<01:11,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 1 Yellow Light, 396.2ms\n",
      "Speed: 5.0ms preprocess, 396.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 40%|██████████████████████████████▋                                              | 110/276 [00:47<01:10,  2.34frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335.7484130859375, 298.4850769042969, 345.27447509765625, 309.0224914550781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.0ms\n",
      "Speed: 0.0ms preprocess, 421.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 40%|██████████████████████████████▉                                              | 111/276 [00:48<01:10,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335.464111328125, 295.5100402832031, 344.80609130859375, 305.9796447753906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 450.5ms\n",
      "Speed: 0.0ms preprocess, 450.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████████████████████▏                                             | 112/276 [00:48<01:12,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[334.60980224609375, 292.34576416015625, 344.5615234375, 303.68499755859375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 414.8ms\n",
      "Speed: 0.0ms preprocess, 414.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████████████████████▌                                             | 113/276 [00:49<01:11,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[334.2364196777344, 290.22100830078125, 343.9668273925781, 301.70751953125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 418.0ms\n",
      "Speed: 0.0ms preprocess, 418.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████████████████████▊                                             | 114/276 [00:49<01:11,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[333.79193115234375, 286.9610900878906, 343.5655517578125, 298.4662780761719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 413.5ms\n",
      "Speed: 0.0ms preprocess, 413.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████████████████████                                             | 115/276 [00:49<01:09,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[333.64239501953125, 283.79962158203125, 343.47076416015625, 295.43328857421875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 453.3ms\n",
      "Speed: 0.0ms preprocess, 453.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████████████████████▎                                            | 116/276 [00:50<01:10,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[333.0982666015625, 280.87811279296875, 343.47686767578125, 292.88446044921875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 418.2ms\n",
      "Speed: 0.8ms preprocess, 418.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████████████████████▋                                            | 117/276 [00:50<01:10,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332.61663818359375, 277.215576171875, 343.06805419921875, 289.92724609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.9ms\n",
      "Speed: 0.0ms preprocess, 416.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████████████████████▉                                            | 118/276 [00:51<01:09,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332.6005859375, 274.24554443359375, 342.08355712890625, 286.489501953125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 412.8ms\n",
      "Speed: 0.0ms preprocess, 412.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 43%|█████████████████████████████████▏                                           | 119/276 [00:51<01:08,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332.1141357421875, 270.8252258300781, 342.38177490234375, 283.2294616699219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 405.7ms\n",
      "Speed: 6.4ms preprocess, 405.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 43%|█████████████████████████████████▍                                           | 120/276 [00:52<01:08,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.9225158691406, 266.6626892089844, 341.9760437011719, 279.5755310058594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 418.7ms\n",
      "Speed: 1.0ms preprocess, 418.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████████████████████▊                                           | 121/276 [00:52<01:07,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.14697265625, 263.05609130859375, 342.1234130859375, 275.79803466796875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 496.6ms\n",
      "Speed: 1.0ms preprocess, 496.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████████████████████                                           | 122/276 [00:53<01:11,  2.16frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.2331237792969, 258.23651123046875, 341.4840393066406, 272.267578125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 401.3ms\n",
      "Speed: 0.0ms preprocess, 401.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████████████████████▎                                          | 123/276 [00:53<01:08,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.64532470703125, 254.13656616210938, 341.41156005859375, 267.5666198730469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 399.7ms\n",
      "Speed: 0.0ms preprocess, 399.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████████████████████▌                                          | 124/276 [00:53<01:07,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.114990234375, 248.35223388671875, 341.5762939453125, 262.86370849609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 408.8ms\n",
      "Speed: 2.0ms preprocess, 408.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████████████████████▊                                          | 125/276 [00:54<01:06,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328.4082336425781, 243.3780517578125, 341.0627136230469, 257.9102783203125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 403.9ms\n",
      "Speed: 1.0ms preprocess, 403.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████████████████████▏                                         | 126/276 [00:54<01:05,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328.25152587890625, 237.82745361328125, 340.30694580078125, 252.66943359375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 434.7ms\n",
      "Speed: 1.0ms preprocess, 434.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████████████████████▍                                         | 127/276 [00:55<01:05,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[327.76971435546875, 231.6038818359375, 340.12469482421875, 246.6046142578125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 429.8ms\n",
      "Speed: 1.0ms preprocess, 429.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████████████████████▋                                         | 128/276 [00:55<01:05,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.49346923828125, 253.9835205078125, 341.47064208984375, 267.56494140625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 427.9ms\n",
      "Speed: 1.0ms preprocess, 427.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████████████████████▉                                         | 129/276 [00:56<01:05,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.50146484375, 253.99258422851562, 341.4580078125, 267.5626525878906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 410.5ms\n",
      "Speed: 2.0ms preprocess, 410.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████████████████████▎                                        | 130/276 [00:56<01:04,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.49908447265625, 253.991943359375, 341.46038818359375, 267.5626220703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 425.0ms\n",
      "Speed: 0.0ms preprocess, 425.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████████████████████▌                                        | 131/276 [00:57<01:04,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.49908447265625, 253.991943359375, 341.46038818359375, 267.5626220703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.5ms\n",
      "Speed: 0.0ms preprocess, 422.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████████████████████▊                                        | 132/276 [00:57<01:03,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.5306091308594, 254.00405883789062, 341.4614562988281, 267.5440368652344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 406.0ms\n",
      "Speed: 0.0ms preprocess, 406.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 48%|█████████████████████████████████████                                        | 133/276 [00:57<01:02,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.5728759765625, 254.0435791015625, 341.4361572265625, 267.55572509765625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.9ms\n",
      "Speed: 0.0ms preprocess, 417.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████████████████████▍                                       | 134/276 [00:58<01:01,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.53887939453125, 254.05322265625, 341.41290283203125, 267.57470703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 432.3ms\n",
      "Speed: 0.0ms preprocess, 432.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████████████████████▋                                       | 135/276 [00:58<01:01,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.566650390625, 254.0643768310547, 341.38421630859375, 267.55865478515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 415.2ms\n",
      "Speed: 0.0ms preprocess, 415.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████████████████████▉                                       | 136/276 [00:59<01:00,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4921875, 254.05361938476562, 341.44537353515625, 267.5691223144531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.8ms\n",
      "Speed: 0.0ms preprocess, 416.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████████████████████████▏                                      | 137/276 [00:59<01:00,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4089660644531, 254.037109375, 341.5118103027344, 267.58221435546875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 405.1ms\n",
      "Speed: 2.0ms preprocess, 405.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████████████████████████▌                                      | 138/276 [01:00<00:59,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.41302490234375, 254.04183959960938, 341.50970458984375, 267.5872497558594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.7ms\n",
      "Speed: 1.0ms preprocess, 417.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████████████████████████▊                                      | 139/276 [01:00<00:59,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4375, 254.0522918701172, 341.5032958984375, 267.58868408203125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 434.8ms\n",
      "Speed: 0.8ms preprocess, 434.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████████████████████████                                      | 140/276 [01:00<00:59,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4483337402344, 254.0558624267578, 341.4939270019531, 267.58746337890625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.0ms\n",
      "Speed: 0.0ms preprocess, 421.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████████████████████████▎                                     | 141/276 [01:01<00:59,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.44866943359375, 254.05601501464844, 341.4935302734375, 267.58740234375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.7ms\n",
      "Speed: 0.0ms preprocess, 417.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████████████████████████▌                                     | 142/276 [01:01<00:58,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42364501953125, 254.02598571777344, 341.50213623046875, 267.5860595703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 412.3ms\n",
      "Speed: 0.0ms preprocess, 412.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████████████████████████▉                                     | 143/276 [01:02<00:57,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42864990234375, 254.02330017089844, 341.50054931640625, 267.5858154296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.8ms\n",
      "Speed: 0.0ms preprocess, 416.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████████████████████████▏                                    | 144/276 [01:02<00:57,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4119567871094, 254.01498413085938, 341.5021057128906, 267.5835266113281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.2ms\n",
      "Speed: 0.0ms preprocess, 422.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████████████████████████▍                                    | 145/276 [01:03<00:56,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42205810546875, 254.02029418945312, 341.48785400390625, 267.5831604003906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 420.3ms\n",
      "Speed: 0.0ms preprocess, 420.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████████████████████████▋                                    | 146/276 [01:03<00:56,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4393310546875, 254.04922485351562, 341.461669921875, 267.5791931152344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 419.0ms\n",
      "Speed: 4.4ms preprocess, 419.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████████████████████████████████████████                                    | 147/276 [01:04<00:55,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.43499755859375, 254.04566955566406, 341.46038818359375, 267.5767822265625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.6ms\n",
      "Speed: 0.0ms preprocess, 416.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████████████████████████▎                                   | 148/276 [01:04<00:56,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.438720703125, 254.04908752441406, 341.459716796875, 267.5787353515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.4ms\n",
      "Speed: 0.0ms preprocess, 417.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████████████████████████▌                                   | 149/276 [01:04<00:55,  2.30frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.434814453125, 254.04556274414062, 341.4605712890625, 267.5768737792969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 439.0ms\n",
      "Speed: 0.0ms preprocess, 439.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████████████████████████▊                                   | 150/276 [01:05<00:55,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4039306640625, 254.04443359375, 341.46875, 267.5855712890625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.0ms\n",
      "Speed: 1.0ms preprocess, 422.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████████████████████████▏                                  | 151/276 [01:05<00:55,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.415283203125, 254.04708862304688, 341.45654296875, 267.5824890136719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 419.6ms\n",
      "Speed: 1.0ms preprocess, 419.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████████████████████████▍                                  | 152/276 [01:06<00:54,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4171142578125, 254.04823303222656, 341.4486083984375, 267.5814208984375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 440.2ms\n",
      "Speed: 0.0ms preprocess, 440.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████████████████████████▋                                  | 153/276 [01:06<00:54,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4429626464844, 254.05459594726562, 341.4367370605469, 267.5798034667969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.8ms\n",
      "Speed: 0.0ms preprocess, 422.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 56%|██████████████████████████████████████████▉                                  | 154/276 [01:07<00:53,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42156982421875, 254.0526123046875, 341.44708251953125, 267.5806884765625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.9ms\n",
      "Speed: 0.0ms preprocess, 417.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████████████████████████▏                                 | 155/276 [01:07<00:53,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4402770996094, 254.05368041992188, 341.4432678222656, 267.5799255371094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 431.6ms\n",
      "Speed: 0.0ms preprocess, 431.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 57%|███████████████████████████████████████████▌                                 | 156/276 [01:07<00:53,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42144775390625, 254.05258178710938, 341.44720458984375, 267.5806579589844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 439.1ms\n",
      "Speed: 0.0ms preprocess, 439.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 57%|███████████████████████████████████████████▊                                 | 157/276 [01:08<00:52,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.44024658203125, 254.05368041992188, 341.44329833984375, 267.5799255371094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 431.1ms\n",
      "Speed: 0.0ms preprocess, 431.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████████████████████████                                 | 158/276 [01:08<00:52,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4434509277344, 254.05001831054688, 341.4610290527344, 267.5812683105469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 425.5ms\n",
      "Speed: 1.0ms preprocess, 425.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████████████████████████▎                                | 159/276 [01:09<00:51,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.40570068359375, 254.0381317138672, 341.45501708984375, 267.57086181640625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 415.0ms\n",
      "Speed: 0.0ms preprocess, 415.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████████████████████████▋                                | 160/276 [01:09<00:51,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4193115234375, 254.05580139160156, 341.413330078125, 267.56103515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 414.1ms\n",
      "Speed: 0.0ms preprocess, 414.1ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████████████████████████▉                                | 161/276 [01:10<00:50,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4258728027344, 254.0328369140625, 341.4149475097656, 267.5582275390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 434.6ms\n",
      "Speed: 2.0ms preprocess, 434.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████████████████████████▏                               | 162/276 [01:10<00:50,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42437744140625, 254.02676391601562, 341.40875244140625, 267.5600891113281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 501.0ms\n",
      "Speed: 1.0ms preprocess, 501.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████████████████████████▍                               | 163/276 [01:11<00:52,  2.16frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4185791015625, 254.02685546875, 341.43536376953125, 267.56719970703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 428.2ms\n",
      "Speed: 1.0ms preprocess, 428.2ms inference, 14.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████████████████████████▊                               | 164/276 [01:11<00:52,  2.15frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4642639160156, 254.02700805664062, 341.3752136230469, 267.5528869628906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 395.1ms\n",
      "Speed: 1.0ms preprocess, 395.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████████████████████████████                               | 165/276 [01:12<00:50,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.49053955078125, 254.0612335205078, 341.385986328125, 267.56988525390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 404.3ms\n",
      "Speed: 1.0ms preprocess, 404.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████████████████████████████▎                              | 166/276 [01:12<00:49,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4366760253906, 254.04905700683594, 341.4101257324219, 267.5648193359375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 407.0ms\n",
      "Speed: 5.4ms preprocess, 407.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████████████████████████████████████████████▌                              | 167/276 [01:12<00:47,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4569091796875, 254.03907775878906, 341.392822265625, 267.55224609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.3ms\n",
      "Speed: 0.0ms preprocess, 416.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████████████████████████████████████████████▊                              | 168/276 [01:13<00:47,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4247741699219, 254.00332641601562, 341.4706726074219, 267.5796203613281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 414.3ms\n",
      "Speed: 0.0ms preprocess, 414.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████████████████████████████▏                             | 169/276 [01:13<00:46,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3778991699219, 253.98895263671875, 341.4384460449219, 267.5660400390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 438.7ms\n",
      "Speed: 0.0ms preprocess, 438.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████████████████████████████▍                             | 170/276 [01:14<00:46,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3313293457031, 253.99002075195312, 341.5296325683594, 267.5641174316406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 438.4ms\n",
      "Speed: 0.0ms preprocess, 438.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████████████████████████████▋                             | 171/276 [01:14<00:46,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.27362060546875, 253.98822021484375, 341.60076904296875, 267.57501220703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 400.3ms\n",
      "Speed: 0.0ms preprocess, 400.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████████████████████████████▉                             | 172/276 [01:15<00:45,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.26806640625, 253.95770263671875, 341.68182373046875, 267.56475830078125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.1ms\n",
      "Speed: 1.0ms preprocess, 421.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████████████████████████████▎                            | 173/276 [01:15<00:45,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2377624511719, 253.91476440429688, 341.7098083496094, 267.5411071777344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 409.1ms\n",
      "Speed: 1.0ms preprocess, 409.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████████████████████████████▌                            | 174/276 [01:15<00:44,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2579345703125, 253.95657348632812, 341.699462890625, 267.5533142089844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 425.2ms\n",
      "Speed: 1.0ms preprocess, 425.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████████████████████████████▊                            | 175/276 [01:16<00:44,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.17242431640625, 253.931884765625, 341.72137451171875, 267.53704833984375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 424.6ms\n",
      "Speed: 2.0ms preprocess, 424.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████████████████████████████                            | 176/276 [01:16<00:43,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.1434326171875, 253.91537475585938, 341.71978759765625, 267.5399475097656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 428.4ms\n",
      "Speed: 0.0ms preprocess, 428.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████████████████████████████▍                           | 177/276 [01:17<00:43,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.21533203125, 253.92898559570312, 341.6690673828125, 267.5424499511719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.4ms\n",
      "Speed: 0.0ms preprocess, 422.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████████████████████████████▋                           | 178/276 [01:17<00:42,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2421875, 253.9590301513672, 341.6986083984375, 267.52777099609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 423.0ms\n",
      "Speed: 1.0ms preprocess, 423.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████████████████████████████▉                           | 179/276 [01:18<00:42,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.18975830078125, 253.9263916015625, 341.75640869140625, 267.53717041015625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 406.2ms\n",
      "Speed: 0.0ms preprocess, 406.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████████████████████████████████████████████████▏                          | 180/276 [01:18<00:41,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.21258544921875, 253.9593048095703, 341.6873779296875, 267.51995849609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 429.7ms\n",
      "Speed: 1.0ms preprocess, 429.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████████████████████████████▍                          | 181/276 [01:19<00:41,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.20294189453125, 253.98753356933594, 341.62335205078125, 267.5042724609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 412.5ms\n",
      "Speed: 1.0ms preprocess, 412.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████████████████████████████▊                          | 182/276 [01:19<00:40,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.210205078125, 253.98593139648438, 341.556396484375, 267.4903259277344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 433.7ms\n",
      "Speed: 0.0ms preprocess, 433.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 66%|███████████████████████████████████████████████████                          | 183/276 [01:19<00:40,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2100830078125, 253.99203491210938, 341.604736328125, 267.4967346191406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.7ms\n",
      "Speed: 0.0ms preprocess, 416.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████████████████████████████▎                         | 184/276 [01:20<00:40,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2040100097656, 253.958251953125, 341.6784362792969, 267.4873046875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 451.7ms\n",
      "Speed: 0.0ms preprocess, 451.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████████████████████████████▌                         | 185/276 [01:20<00:40,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.1612548828125, 253.94729614257812, 341.63690185546875, 267.4736022949219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 440.9ms\n",
      "Speed: 1.2ms preprocess, 440.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████████████████████████████▉                         | 186/276 [01:21<00:40,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.1788635253906, 254.00140380859375, 341.6144714355469, 267.48052978515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 438.5ms\n",
      "Speed: 1.0ms preprocess, 438.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████████████████████████████▏                        | 187/276 [01:21<00:39,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.127197265625, 253.9888916015625, 341.5699462890625, 267.46478271484375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 452.8ms\n",
      "Speed: 0.0ms preprocess, 452.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████████████████████████████▍                        | 188/276 [01:22<00:39,  2.20frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.15203857421875, 253.90921020507812, 341.62982177734375, 267.4328308105469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 424.6ms\n",
      "Speed: 0.0ms preprocess, 424.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████████████████████████████▋                        | 189/276 [01:22<00:39,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.077880859375, 253.90982055664062, 341.5906982421875, 267.4507141113281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 431.6ms\n",
      "Speed: 1.7ms preprocess, 431.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████████████████████████████                        | 190/276 [01:23<00:38,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.1001281738281, 253.932373046875, 341.5904235839844, 267.44525146484375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.8ms\n",
      "Speed: 1.9ms preprocess, 421.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████████████████████████████▎                       | 191/276 [01:23<00:38,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.0841979980469, 253.9597930908203, 341.5470275878906, 267.43963623046875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 419.6ms\n",
      "Speed: 0.0ms preprocess, 419.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████████████████████████████▌                       | 192/276 [01:23<00:37,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.10040283203125, 253.955322265625, 341.59564208984375, 267.44427490234375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 423.8ms\n",
      "Speed: 0.0ms preprocess, 423.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████████████████████████████▊                       | 193/276 [01:24<00:36,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.09637451171875, 253.987060546875, 341.60601806640625, 267.42156982421875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.0ms\n",
      "Speed: 1.0ms preprocess, 421.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████                       | 194/276 [01:24<00:36,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2220458984375, 254.01527404785156, 341.55072021484375, 267.427978515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 419.7ms\n",
      "Speed: 0.0ms preprocess, 419.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████████████████████████████▍                      | 195/276 [01:25<00:35,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.1843566894531, 253.99118041992188, 341.5547180175781, 267.4293518066406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 423.3ms\n",
      "Speed: 5.1ms preprocess, 423.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████████████████████████████▋                      | 196/276 [01:25<00:35,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2132263183594, 253.97174072265625, 341.5291442871094, 267.42620849609375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 424.5ms\n",
      "Speed: 0.0ms preprocess, 424.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████████████████████████████▉                      | 197/276 [01:26<00:34,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3038024902344, 254.03457641601562, 341.4988708496094, 267.3827209472656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 430.0ms\n",
      "Speed: 0.0ms preprocess, 430.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████████████████████████████████▏                     | 198/276 [01:26<00:34,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3189697265625, 254.01608276367188, 341.6044921875, 267.4125061035156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 414.0ms\n",
      "Speed: 1.0ms preprocess, 414.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████████████████████████████████▌                     | 199/276 [01:27<00:33,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2544250488281, 254.0029754638672, 341.6155700683594, 267.44061279296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.0ms\n",
      "Speed: 0.0ms preprocess, 417.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████████████████████████████████▊                     | 200/276 [01:27<00:33,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.34674072265625, 254.05911254882812, 341.50543212890625, 267.4321594238281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 406.2ms\n",
      "Speed: 1.0ms preprocess, 406.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████                     | 201/276 [01:27<00:32,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.23602294921875, 254.02035522460938, 341.60992431640625, 267.4432678222656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 416.6ms\n",
      "Speed: 0.0ms preprocess, 416.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████▎                    | 202/276 [01:28<00:32,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3076171875, 254.05126953125, 341.5457763671875, 267.454345703125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 431.8ms\n",
      "Speed: 0.0ms preprocess, 431.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████████████████████████████████▋                    | 203/276 [01:28<00:32,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.32232666015625, 254.05484008789062, 341.54083251953125, 267.4297180175781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 429.5ms\n",
      "Speed: 0.0ms preprocess, 429.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████████████████████████████████▉                    | 204/276 [01:29<00:31,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.2919921875, 254.02841186523438, 341.6639404296875, 267.4233093261719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 413.7ms\n",
      "Speed: 0.0ms preprocess, 413.7ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████████████████████████████████▏                   | 205/276 [01:29<00:31,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4165344238281, 254.02056884765625, 341.6141052246094, 267.428466796875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 513.2ms\n",
      "Speed: 1.0ms preprocess, 513.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████████████████████████████████▍                   | 206/276 [01:30<00:32,  2.13frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.42138671875, 254.02783203125, 341.578125, 267.43121337890625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 404.7ms\n",
      "Speed: 1.0ms preprocess, 404.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████████████████████████████████▊                   | 207/276 [01:30<00:31,  2.19frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.376953125, 253.98382568359375, 341.56201171875, 267.43341064453125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 398.8ms\n",
      "Speed: 0.0ms preprocess, 398.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████████████████████████████████                   | 208/276 [01:31<00:30,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.38726806640625, 254.02078247070312, 341.49151611328125, 267.4394226074219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 405.1ms\n",
      "Speed: 1.0ms preprocess, 405.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████████▎                  | 209/276 [01:31<00:29,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.3349609375, 254.02651977539062, 341.547119140625, 267.4938049316406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 422.0ms\n",
      "Speed: 1.0ms preprocess, 422.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████████▌                  | 210/276 [01:31<00:29,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.4126281738281, 254.00897216796875, 341.4897766113281, 267.45770263671875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 456.4ms\n",
      "Speed: 0.0ms preprocess, 456.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████████▊                  | 211/276 [01:32<00:29,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.39642333984375, 254.1405487060547, 341.61627197265625, 267.50445556640625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 467.2ms\n",
      "Speed: 0.0ms preprocess, 467.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████████████████████████████████████████████████████████▏                 | 212/276 [01:32<00:29,  2.18frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.439453125, 254.1297607421875, 341.531494140625, 267.5018310546875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 437.5ms\n",
      "Speed: 2.0ms preprocess, 437.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████████████████████████████████████████████████████████▍                 | 213/276 [01:33<00:28,  2.19frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.6583251953125, 254.13092041015625, 341.56243896484375, 267.463623046875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 427.4ms\n",
      "Speed: 1.0ms preprocess, 427.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████▋                 | 214/276 [01:33<00:27,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.6767578125, 254.11123657226562, 341.5045166015625, 267.4983825683594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 478.0ms\n",
      "Speed: 0.0ms preprocess, 478.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████▉                 | 215/276 [01:34<00:28,  2.17frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.796142578125, 254.14544677734375, 341.56640625, 267.5233154296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 432.5ms\n",
      "Speed: 1.0ms preprocess, 432.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████████████████████████████████▎                | 216/276 [01:34<00:27,  2.19frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.87469482421875, 254.14581298828125, 341.57196044921875, 267.519287109375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 437.2ms\n",
      "Speed: 1.0ms preprocess, 437.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 79%|████████████████████████████████████████████████████████████▌                | 217/276 [01:35<00:26,  2.20frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.80084228515625, 254.173583984375, 341.50115966796875, 267.50018310546875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 430.3ms\n",
      "Speed: 2.0ms preprocess, 430.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 79%|████████████████████████████████████████████████████████████▊                | 218/276 [01:35<00:26,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.79742431640625, 254.11285400390625, 341.51141357421875, 267.52117919921875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 527.7ms\n",
      "Speed: 1.0ms preprocess, 527.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████████████████████████████████                | 219/276 [01:36<00:27,  2.09frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.8028869628906, 254.21310424804688, 341.4034729003906, 267.5103454589844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 420.4ms\n",
      "Speed: 1.0ms preprocess, 420.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████████████████████████████▍               | 220/276 [01:36<00:26,  2.15frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.1397705078125, 254.30807495117188, 341.48876953125, 267.5434875488281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 419.8ms\n",
      "Speed: 2.0ms preprocess, 419.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████████████████████████████▋               | 221/276 [01:37<00:25,  2.19frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.8526611328125, 254.1770477294922, 341.4154052734375, 267.52740478515625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 427.6ms\n",
      "Speed: 1.4ms preprocess, 427.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████████████████████████████▉               | 222/276 [01:37<00:24,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329.99383544921875, 254.22518920898438, 341.38616943359375, 267.5542907714844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 426.6ms\n",
      "Speed: 2.0ms preprocess, 426.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████████▏              | 223/276 [01:37<00:23,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.05572509765625, 254.25955200195312, 341.40777587890625, 267.5730895996094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 427.8ms\n",
      "Speed: 2.2ms preprocess, 427.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████████▍              | 224/276 [01:38<00:23,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.060546875, 254.26998901367188, 341.40399169921875, 267.5981140136719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 430.7ms\n",
      "Speed: 1.0ms preprocess, 430.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████▊              | 225/276 [01:38<00:22,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.08197021484375, 254.24630737304688, 341.44024658203125, 267.6561584472656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 423.9ms\n",
      "Speed: 2.0ms preprocess, 423.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████              | 226/276 [01:39<00:22,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.1639404296875, 254.1606903076172, 341.3935546875, 267.62518310546875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.9ms\n",
      "Speed: 1.0ms preprocess, 421.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████▎             | 227/276 [01:39<00:21,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.13214111328125, 254.19602966308594, 341.41693115234375, 267.6951904296875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 417.3ms\n",
      "Speed: 1.0ms preprocess, 417.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████████████████████████████████▌             | 228/276 [01:40<00:21,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.3131103515625, 254.08938598632812, 341.3785400390625, 267.6236267089844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 439.1ms\n",
      "Speed: 0.0ms preprocess, 439.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████████████████████████████████▉             | 229/276 [01:40<00:20,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.2340087890625, 254.18418884277344, 341.3203125, 267.613525390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 Yellow Light, 421.9ms\n",
      "Speed: 1.0ms preprocess, 421.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████████████████████████████████████▏            | 230/276 [01:40<00:20,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330.22930908203125, 254.23123168945312, 341.406005859375, 267.7972717285156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 433.9ms\n",
      "Speed: 1.0ms preprocess, 433.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████████████████████████████████▍            | 231/276 [01:41<00:19,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 422.5ms\n",
      "Speed: 1.0ms preprocess, 422.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████████████████████████████████▋            | 232/276 [01:41<00:19,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 426.9ms\n",
      "Speed: 1.0ms preprocess, 426.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████████            | 233/276 [01:42<00:18,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 425.7ms\n",
      "Speed: 1.0ms preprocess, 425.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████▎           | 234/276 [01:42<00:18,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 428.0ms\n",
      "Speed: 1.0ms preprocess, 428.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████▌           | 235/276 [01:43<00:18,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 436.9ms\n",
      "Speed: 1.0ms preprocess, 436.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████▊           | 236/276 [01:43<00:17,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 430.7ms\n",
      "Speed: 1.9ms preprocess, 430.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████           | 237/276 [01:44<00:17,  2.25frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 439.4ms\n",
      "Speed: 1.0ms preprocess, 439.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████▍          | 238/276 [01:44<00:16,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 432.8ms\n",
      "Speed: 1.0ms preprocess, 432.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████████████████████████████████████▋          | 239/276 [01:44<00:16,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 474.8ms\n",
      "Speed: 4.3ms preprocess, 474.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████████████████████████████████████▉          | 240/276 [01:45<00:16,  2.17frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.4ms\n",
      "Speed: 0.0ms preprocess, 410.4ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████████████▏         | 241/276 [01:45<00:15,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 415.4ms\n",
      "Speed: 0.0ms preprocess, 415.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 88%|███████████████████████████████████████████████████████████████████▌         | 242/276 [01:46<00:15,  2.24frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.6ms\n",
      "Speed: 1.0ms preprocess, 409.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 88%|███████████████████████████████████████████████████████████████████▊         | 243/276 [01:46<00:14,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 419.1ms\n",
      "Speed: 1.0ms preprocess, 419.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████         | 244/276 [01:47<00:14,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.8ms\n",
      "Speed: 0.0ms preprocess, 408.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████▎        | 245/276 [01:47<00:13,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 428.1ms\n",
      "Speed: 0.0ms preprocess, 428.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████▋        | 246/276 [01:48<00:13,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.9ms\n",
      "Speed: 0.0ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████▉        | 247/276 [01:48<00:12,  2.27frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 485.7ms\n",
      "Speed: 0.0ms preprocess, 485.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████▏       | 248/276 [01:49<00:12,  2.17frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 414.0ms\n",
      "Speed: 0.0ms preprocess, 414.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████▍       | 249/276 [01:49<00:12,  2.21frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 435.3ms\n",
      "Speed: 1.9ms preprocess, 435.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████████████████████████████████████████████████████████████████▋       | 250/276 [01:49<00:11,  2.22frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.7ms\n",
      "Speed: 1.0ms preprocess, 410.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████       | 251/276 [01:50<00:11,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 436.1ms\n",
      "Speed: 0.2ms preprocess, 436.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████▎      | 252/276 [01:50<00:10,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.2ms\n",
      "Speed: 1.0ms preprocess, 410.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████████████████████████████████████▌      | 253/276 [01:51<00:10,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 394.3ms\n",
      "Speed: 2.2ms preprocess, 394.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████████████████████████████████████▊      | 254/276 [01:51<00:09,  2.29frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 408.6ms\n",
      "Speed: 0.0ms preprocess, 408.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████▏     | 255/276 [01:52<00:09,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.7ms\n",
      "Speed: 1.0ms preprocess, 404.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████████████████████████████████████▍     | 256/276 [01:52<00:08,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 406.5ms\n",
      "Speed: 0.0ms preprocess, 406.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████████████████████████████████████▋     | 257/276 [01:52<00:08,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.9ms\n",
      "Speed: 0.2ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████████████████████████████████████▉     | 258/276 [01:53<00:07,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 396.2ms\n",
      "Speed: 1.3ms preprocess, 396.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████████▎    | 259/276 [01:53<00:07,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 423.8ms\n",
      "Speed: 0.1ms preprocess, 423.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████████▌    | 260/276 [01:54<00:06,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 459.8ms\n",
      "Speed: 0.0ms preprocess, 459.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████▊    | 261/276 [01:54<00:06,  2.26frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 447.3ms\n",
      "Speed: 0.4ms preprocess, 447.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████    | 262/276 [01:55<00:06,  2.23frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 393.7ms\n",
      "Speed: 0.0ms preprocess, 393.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▎   | 263/276 [01:55<00:05,  2.28frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 391.8ms\n",
      "Speed: 0.0ms preprocess, 391.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▋   | 264/276 [01:55<00:05,  2.31frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 405.8ms\n",
      "Speed: 1.0ms preprocess, 405.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 265/276 [01:56<00:04,  2.32frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 410.6ms\n",
      "Speed: 0.0ms preprocess, 410.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▏  | 266/276 [01:56<00:04,  2.33frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 390.2ms\n",
      "Speed: 0.0ms preprocess, 390.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▍  | 267/276 [01:57<00:03,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.0ms\n",
      "Speed: 0.0ms preprocess, 404.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▊  | 268/276 [01:57<00:03,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 388.6ms\n",
      "Speed: 0.0ms preprocess, 388.6ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 97%|███████████████████████████████████████████████████████████████████████████  | 269/276 [01:58<00:02,  2.37frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 404.8ms\n",
      "Speed: 0.0ms preprocess, 404.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▎ | 270/276 [01:58<00:02,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 409.8ms\n",
      "Speed: 0.0ms preprocess, 409.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▌ | 271/276 [01:58<00:02,  2.36frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 417.8ms\n",
      "Speed: 0.0ms preprocess, 417.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████████▉ | 272/276 [01:59<00:01,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 402.8ms\n",
      "Speed: 0.0ms preprocess, 402.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▏| 273/276 [01:59<00:01,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 411.4ms\n",
      "Speed: 0.0ms preprocess, 411.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▍| 274/276 [02:00<00:00,  2.35frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 402.6ms\n",
      "Speed: 0.0ms preprocess, 402.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████▋| 275/276 [02:00<00:00,  2.37frame/s]\u001b[A\u001b[A\u001b[A\n",
      "0: 640x640 (no detections), 403.2ms\n",
      "Speed: 0.0ms preprocess, 403.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 276/276 [02:01<00:00,  2.37frame/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# 입력 동영상 캡처\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 출력 동영상 코덱 및 VideoWriter 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 또는 'XVID'\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))\n",
    "\n",
    "# 초기화 최적화\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame')\n",
    "\n",
    "def process_frame(frame, pbar):\n",
    "    resized_frame = cv2.resize(frame, (640, 640))\n",
    "    results = model(resized_frame)\n",
    "\n",
    "    if isinstance(results, list):  # Check if results is a list\n",
    "        results = results[0]\n",
    "\n",
    "#     if 'boxes' in results.names:\n",
    "#         for box, cls, conf in zip(results.boxes, results.cls, results.conf):\n",
    "#             x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "#             cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # 두께를 3으로 설정\n",
    "#             text = f'{model.names[int(cls)]}: {conf:.2f}'\n",
    "#             cv2.putText(resized_frame, text, (x1, y1 - 15),  # 높이 조절\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  # 글자 크기를 1로 설정\n",
    "            \n",
    "    if results.boxes.data.tolist():\n",
    "        for det in results.boxes.xyxy:\n",
    "            print(det.tolist())\n",
    "            x1, y1, x2, y2, conf, cls = det.tolist()+['', results.boxes.cls.data[0].cpu()]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # 두께를 3으로 설정\n",
    "            # text = f'{model.names[int(cls)]}: {conf:.2f}'\n",
    "            \n",
    "            text = results.names[int(cls)]\n",
    "            cv2.putText(resized_frame, text, (x1, y1 - 15),  # 높이 조절\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  # 글자 크기를 1로 설정\n",
    "#     print(\"aaaaaaaaaaaaaaaa\")\n",
    "#     print(\"aaaaaaaaaaaaaaaa\")\n",
    "#     print(\"====\")\n",
    "    #     else:\n",
    "    #         print(\"Results format not recognized.\")\n",
    "\n",
    "    out.write(resized_frame)\n",
    "    cv2.imshow('Object Detection', resized_frame)\n",
    "    pbar.update(1)\n",
    "\n",
    "# 프레임 처리\n",
    "while ret:\n",
    "    process_frame(frame, pbar)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e668c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Green Light', 1: 'Left turn', 2: 'Red Light', 3: 'Yellow Light'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f51d1506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Green Light'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f072e2",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b3d4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 동영상 캡처\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 초기화 최적화\n",
    "ret, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "298bbcd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results[0].boxes.xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fda4b2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[582.88623046875,\n",
       "  374.11798095703125,\n",
       "  595.02197265625,\n",
       "  386.14202880859375,\n",
       "  0.5253190994262695,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48c07ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[5.8289e+02, 3.7412e+02, 5.9502e+02, 3.8614e+02, 5.2532e-01, 0.0000e+00]])\n",
       "cls: tensor([0.])\n",
       "conf: tensor([0.5253])\n",
       "data: tensor([[5.8289e+02, 3.7412e+02, 5.9502e+02, 3.8614e+02, 5.2532e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: tensor([ 720, 1280])\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[588.9541, 380.1300,  12.1357,  12.0240]])\n",
       "xywhn: tensor([[0.4601, 0.5280, 0.0095, 0.0167]])\n",
       "xyxy: tensor([[582.8862, 374.1180, 595.0220, 386.1420]])\n",
       "xyxyn: tensor([[0.4554, 0.5196, 0.4649, 0.5363]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91d9117c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.cls.data[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7f389e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[582.8862, 374.1180, 595.0220, 386.1420]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xyxy.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a9281f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Green Light, 441.8ms\n",
      "Speed: 0.0ms preprocess, 441.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290.7869873046875, 331.91253662109375, 298.12890625, 341.99761962890625]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 34\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#cv2.imshow('Object Detection', resized_frame)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m#pbar.update(1)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#     return 0, resized_frame\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 프레임 처리\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ret:\n\u001b[1;32m---> 34\u001b[0m     is_detected, img \u001b[38;5;241m=\u001b[39m process_frame(frame, pbar)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#     if is_detected:\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#         print(\"찾았다\")\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# 입력 동영상 캡처\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 초기화 최적화\n",
    "ret, frame = cap.read()\n",
    "\n",
    "def process_frame(frame, pbar):\n",
    "    resized_frame = cv2.resize(frame, (640, 640))\n",
    "    results = model(resized_frame)\n",
    "\n",
    "    if isinstance(results, list):  # Check if results is a list\n",
    "        results = results[0]\n",
    "\n",
    "    #if results.boxes.xyxy.cpu():\n",
    "    if results.boxes.data.tolist():\n",
    "        for det in results.boxes.xyxy:\n",
    "            print(det.tolist())\n",
    "            x1, y1, x2, y2, conf, cls = det.tolist()+['', results.boxes.cls.data[0].cpu()]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # 두께를 3으로 설정\n",
    "            # text = f'{model.names[int(cls)]}: {conf:.2f}'\n",
    "            text = '0'\n",
    "            cv2.putText(resized_frame, text, (x1, y1 - 15),  # 높이 조절\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  # 글자 크기를 1로 설정\n",
    "        return 1, resized_frame\n",
    "\n",
    "    out.write(resized_frame)\n",
    "    #cv2.imshow('Object Detection', resized_frame)\n",
    "    #pbar.update(1)\n",
    "    return 0, resized_frame\n",
    "\n",
    "# 프레임 처리\n",
    "while ret:\n",
    "    is_detected, img = process_frame(frame, pbar)\n",
    "#     if is_detected:\n",
    "#         print(\"찾았다\")\n",
    "#         break\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "print(ret, frame)\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d587af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc1e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b59e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9064a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 동영상 캡처\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 초기화 최적화\n",
    "ret, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f25dc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "small_image = cv2.resize(frame, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56f79a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(frame)\n",
    "image.save(\"output_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb8769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Green Light, 276.3ms\n",
      "Speed: 1.0ms preprocess, 276.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "679d1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([582.8862, 374.1180, 595.0220, 386.1420])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa5fee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[5.8289e+02, 3.7412e+02, 5.9502e+02, 3.8614e+02, 5.2532e-01, 0.0000e+00]])\n",
       "cls: tensor([0.])\n",
       "conf: tensor([0.5253])\n",
       "data: tensor([[5.8289e+02, 3.7412e+02, 5.9502e+02, 3.8614e+02, 5.2532e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: tensor([ 720, 1280])\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[588.9541, 380.1300,  12.1357,  12.0240]])\n",
       "xywhn: tensor([[0.4601, 0.5280, 0.0095, 0.0167]])\n",
       "xyxy: tensor([[582.8862, 374.1180, 595.0220, 386.1420]])\n",
       "xyxyn: tensor([[0.4554, 0.5196, 0.4649, 0.5363]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c08fea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " _keys: ('boxes', 'masks', 'probs', 'keypoints')\n",
       " boxes: ultralytics.yolo.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'Green Light', 1: 'Left turn', 2: 'Red Light', 3: 'Yellow Light'}\n",
       " orig_img: array([[[218, 150,  73],\n",
       "         [218, 150,  73],\n",
       "         [218, 150,  73],\n",
       "         ...,\n",
       "         [240, 184, 119],\n",
       "         [243, 187, 122],\n",
       "         [229, 173, 108]],\n",
       " \n",
       "        [[218, 150,  73],\n",
       "         [218, 150,  73],\n",
       "         [218, 150,  73],\n",
       "         ...,\n",
       "         [221, 165, 100],\n",
       "         [242, 186, 121],\n",
       "         [244, 188, 123]],\n",
       " \n",
       "        [[217, 149,  72],\n",
       "         [217, 149,  72],\n",
       "         [217, 149,  72],\n",
       "         ...,\n",
       "         [200, 144,  79],\n",
       "         [226, 170, 105],\n",
       "         [246, 190, 125]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         ...,\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6]],\n",
       " \n",
       "        [[ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         ...,\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6]],\n",
       " \n",
       "        [[ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         [ 14,   9,   8],\n",
       "         ...,\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6],\n",
       "         [  8,   5,   6]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " speed: {'preprocess': 0.9894371032714844, 'inference': 307.9080581665039, 'postprocess': 0.9984970092773438}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa79250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75966094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6584c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0frame [00:18, ?frame/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 초기화 최적화\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame')\n",
    "\n",
    "def process_frame(frame, pbar):\n",
    "    resized_frame = cv2.resize(frame, (640, 640))\n",
    "    results = model(resized_frame)\n",
    "\n",
    "    if isinstance(results, list):  # Check if results is a list\n",
    "        results = results[0]\n",
    "\n",
    "    if 'xyxy' in results.names:\n",
    "        for det in results.xyxy[0]:\n",
    "            x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # 두께를 3으로 설정\n",
    "            text = f'{model.names[int(cls)]}: {conf:.2f}'\n",
    "            cv2.putText(resized_frame, text, (x1, y1 - 15),  # 높이 조절\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  # 글자 크기를 1로 설정\n",
    "\n",
    "    out.write(resized_frame)\n",
    "    cv2.imshow('Object Detection', resized_frame)\n",
    "    pbar.update(1)\n",
    "\n",
    "# 프레임 처리\n",
    "while ret:\n",
    "    process_frame(frame, pbar)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7e8cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0frame [00:00, ?frame/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 초기화 최적화\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), unit='frame')\n",
    "\n",
    "# 프레임 처리\n",
    "while ret:\n",
    "    process_frame(frame, pbar)\n",
    "    ret, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f15bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76da83fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17ae7da8610>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "974da60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16556\\1589612196.py:2: UserWarning: Matplotlib is currently using nbAgg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(small_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "723d2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Green Light, 507.2ms\n",
      "Speed: 1.7ms preprocess, 507.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "resized_frame = cv2.resize(frame, (640, 640))\n",
    "results = model(resized_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4cfc1455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results format not recognized.\n"
     ]
    }
   ],
   "source": [
    "if isinstance(results, list):  # Check if results is a list\n",
    "    results = results[0]\n",
    "\n",
    "if 'xyxy' in results.names:\n",
    "    for det in results.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)  # 두께를 3으로 설정\n",
    "        text = f'{model.names[int(cls)]}: {conf:.2f}'\n",
    "        cv2.putText(resized_frame, text, (x1, y1 - 15),  # 높이 조절\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)  # 글자 크기를 1로 설정\n",
    "else:\n",
    "    print(\"Results format not recognized.\")\n",
    "\n",
    "#out.write(resized_frame)\n",
    "#cv2.imshow('Object Detection', resized_frame)\n",
    "#pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a13d75a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Green Light', 1: 'Left turn', 2: 'Red Light', 3: 'Yellow Light'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
